{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying YSOs with a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#System/general imports\n",
    "import math\n",
    "import imf\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "import time\n",
    "\n",
    "#Data imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# import tables\n",
    "\n",
    "#Astro imports\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from isochrones import parsec\n",
    "from isochrones.mist import MIST_Isochrone\n",
    "from isochrones.parsec import Parsec_Isochrone\n",
    "mist = Parsec_Isochrone()\n",
    "\n",
    "def getmagerror(flux,eflux):\n",
    "    return (-2.5*np.log10(flux-eflux)+2.5*np.log10(flux+eflux))/2\n",
    "\n",
    "\n",
    "# device = torch.device('cuda:0')\n",
    "\n",
    "# import pymultinest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88089, 6])\n",
      "torch.Size([87564, 6])\n",
      "torch.Size([88112, 6])\n"
     ]
    }
   ],
   "source": [
    "clusterx ,clustery =pickle.load(open('ysotrainf1ms.pickle', 'rb'))\n",
    "clusterx1,clustery1=pickle.load(open('ysotrainf2ms.pickle', 'rb'))\n",
    "clusterx2,clustery2=pickle.load(open('ysotrainf3ms.pickle', 'rb'))\n",
    "\n",
    "print(clustery.size())\n",
    "print(clustery1.size())\n",
    "print(clustery2.size())\n",
    "\n",
    "# print(-2.5*np.log10(10**(-mist.mag['G'](mass, 8, feh, distance, AV)/2.5)))\n",
    "# print(-2.5*np.log10(10**(-mist.mag['G'](mass, 8.3, feh, distance, AV)/2.5)))\n",
    "# print(-2.5*np.log10(10**(-mist.mag['G'](mass, 7.5, feh, distance, AV)/2.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used to generate the clusters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "size = 300000\n",
    "mass = np.random.uniform(low=.08,high=3,size=size)\n",
    "age = np.random.uniform(low=6, high=10, size = size)\n",
    "feh = np.random.uniform(low=-2.5, high = .5, size = size)\n",
    "distance = np.random.uniform(low = 50, high = 1000, size = size)\n",
    "AV = np.random.uniform(low=0, high = 20, size = size)\n",
    "\n",
    "clx = np.recarray(size, \n",
    "                 dtype= [('g', float), ('bp', float), ('rp', float), ('j', float),\n",
    "                         ('h', float), ('k', float), ('w1', float), ('w2', float),\n",
    "                         ('w3', float), ('parallax', float),('mass', float),\n",
    "                         ('massratio',float), ('age',float), ('feh', float),\n",
    "                         ('av',float),('teff', float), ('logg', float),\n",
    "                         ('distance', float), ('logl', float), ('radius', float)])\n",
    "clx.mass = mass #Intrinsic properterties - random\n",
    "clx.age = age\n",
    "clx.feh = feh\n",
    "clx.av = AV \n",
    "clx.distance=distance\n",
    "\n",
    "\n",
    "clx.g=-2.5*np.log10(10**(-mist.mag['G'](mass, age, feh, distance, AV)/2.5))\n",
    "#test=-2.5*np.log10(10**(-mist.mag['G'](mass, 8, feh, distance, AV)/2.5))\n",
    "clx.bp=-2.5*np.log10(10**(-mist.mag['BP'](mass, age, feh, distance, AV)/2.5))\n",
    "clx.rp=-2.5*np.log10(10**(-mist.mag['RP'](mass, age, feh, distance, AV)/2.5))\n",
    "clx.j=-2.5*np.log10(10**(-mist.mag['J'](mass, age, feh, distance, AV)/2.5))\n",
    "clx.h=-2.5*np.log10(10**(-mist.mag['H'](mass, age, feh, distance, AV)/2.5))\n",
    "clx.k=-2.5*np.log10(10**(-mist.mag['K'](mass, age, feh, distance, AV)/2.5))\n",
    "clx.w1=-2.5*np.log10(10**(-mist.mag['W1'](mass, age, feh, distance, AV)/2.5))\n",
    "clx.w2=-2.5*np.log10(10**(-mist.mag['W2'](mass, age, feh, distance, AV)/2.5))\n",
    "clx.w3=-2.5*np.log10(10**(-mist.mag['W3'](mass, age, feh, distance, AV)/2.5))\n",
    "clx.teff=mist.Teff(mass, age, feh)\n",
    "clx.logg=mist.logg(mass, age, feh)\n",
    "clx.logl=mist.logL(mass, age, feh)\n",
    "clx.radius=mist.radius(mass, age, feh)\n",
    "clx.parallax=1000/distance\n",
    "\n",
    "clx = clx[np.where((np.isfinite(clx.g)==True) & (np.isfinite(clx.teff)==True) & \n",
    "                   np.isfinite(clx.logg)==True)[0]]\n",
    "\n",
    "clx['g'][np.where(clx.g>19)[0]]=float('NaN')#what is this doing?\n",
    "clx['bp'][np.where(clx.bp>20.5)[0]]=float('NaN')#I think this is just saying that there should\n",
    "clx['rp'][np.where(clx.rp>17.5)[0]]=float('NaN')#be some values where these terms cannot be\n",
    "clx['j'][np.where(clx.j>17)[0]]=float('NaN')\n",
    "clx['h'][np.where(clx.h>16)[0]]=float('NaN')\n",
    "clx['k'][np.where(clx.k>16)[0]]=float('NaN')\n",
    "clx['w1'][np.where(clx.w1>16)[0]]=float('NaN')\n",
    "clx['w2'][np.where(clx.w2>16)[0]]=float('NaN')\n",
    "clx['w3'][np.where(clx.w3>13.5)[0]]=float('NaN')\n",
    "clx=clx[np.where(np.isfinite(clx.g)==True)[0]]\n",
    "clx['bp'][np.where(np.isfinite(clx.bp)==False)[0]]=21\n",
    "clx['rp'][np.where(np.isfinite(clx.rp)==False)[0]]=18\n",
    "clx['j'][np.where(np.isfinite(clx.j)==False)[0]]=17.5\n",
    "clx['h'][np.where(np.isfinite(clx.h)==False)[0]]=16.5\n",
    "clx['k'][np.where(np.isfinite(clx.k)==False)[0]]=16.5\n",
    "clx['w1'][np.where(np.isfinite(clx.w1)==False)[0]]=16.5\n",
    "clx['w2'][np.where(np.isfinite(clx.w2)==False)[0]]=16.5\n",
    "clx['w3'][np.where(np.isfinite(clx.w3)==False)[0]]=14\n",
    "clx['radius'][np.where(clx.radius<0.5)[0]]=0.5\n",
    "clx['logl'][np.where(clx.logl<-1.54)[0]]=-1.54\n",
    "k=np.where(clx.g-5*(np.log10(1000/clx.parallax)-1)>10)[0]\n",
    "clx['radius'][k]=0.5\n",
    "clx['logl'][k]=-1.54\n",
    "size=len(clx)\n",
    "\n",
    "clusterx = torch.Tensor(size, 1, 12)\n",
    "clustery = torch.Tensor(size, 6)\n",
    "for a in range(size):\n",
    "    clusterx[a][0][0]=.5\n",
    "    clusterx[a][0][1]=.5\n",
    "    clusterx[a][0][2]=.5\n",
    "    clusterx[a][0][3]=.5\n",
    "    clusterx[a][0][4]=.5\n",
    "    clusterx[a][0][5]=.5\n",
    "    clusterx[a][0][6]=.5\n",
    "    clusterx[a][0][7]=.5#why .5?\n",
    "    clusterx[a][0][8]=.5\n",
    "    clusterx[a][0][9]=.5\n",
    "    \n",
    "    clusterx[a][0][0]=clx['g'][a]/21-.5#I don't really understand what all these weights are\n",
    "    clusterx[a][0][1]=clx['bp'][a]/21-.5\n",
    "    clusterx[a][0][2]=clx['rp'][a]/18-.5\n",
    "    clusterx[a][0][3]=clx['j'][a]/17.5-0.5\n",
    "    clusterx[a][0][4]=clx['h'][a]/16.5-0.5\n",
    "    clusterx[a][0][5]=clx['k'][a]/16.5-0.5\n",
    "    clusterx[a][0][6]=clx['w1'][a]/16.5-0.5\n",
    "    clusterx[a][0][7]=clx['w2'][a]/16.5-0.5\n",
    "    clusterx[a][0][8]=clx['w3'][a]/14-0.5\n",
    "    clusterx[a][0][9]=clx['parallax'][a]/20-0.5\n",
    "    clusterx[a][0][10]=(clx.radius[a]-0.2)/5-0.5\n",
    "    clusterx[a][0][11]=clx.logl[a]/4\n",
    "    clustery[a][0]=(clx.age[a]-6)/2-0.5\n",
    "    clustery[a][1]=clx.av[a]/20-0.5\n",
    "    clustery[a][2]=clx.mass[a]/3-0.5\n",
    "    clustery[a][3]=(np.log10(clx.teff[a])-3.4)/0.7-0.5\n",
    "    clustery[a][4]=(clx.logg[a]-3)/2-0.5\n",
    "    clustery[a][5]=(clx.feh[a]+2.5)/3-0.5\n",
    "    \n",
    "# pickle.dump([clusterx, clustery], open('ysotrainf3ms.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our neural network, taking twelve inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape = (1,12)):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1,8,3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8,16,3, padding = 1)\n",
    "        self.conv3 = nn.Conv1d(16,32,3,padding =1)\n",
    "        n_size =self._get_conv_output(input_shape)\n",
    "        self.fc1 = nn.Linear(n_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 6)\n",
    "    \n",
    "    #Generate input sample and forward to get shape\n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = torch.rand(bs, *shape)\n",
    "        output_feat = self._forward_features(input)\n",
    "        n_size = output_feat.data.view(bs, -1).size(1)\n",
    "        return n_size\n",
    "    \n",
    "    def _forward_features(self, x):\n",
    "        x = F.max_pool1d(F.relu(self.conv2(F.relu(self.conv1(x)))),2)\n",
    "        x = F.relu(F.max_pool1d(self.conv3(x), 2))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "#Initialize model\n",
    "BAD_LOSS= 100000000\n",
    "model = Net()#initialize our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model=model.to(device)\n",
    "clusterx = clusterx.to(device)\n",
    "clustery = clustery.to(device)\n",
    "clusterx1 = clusterx1.to(device)\n",
    "clustery1 = clustery1.to(device)\n",
    "clusterx2 = clusterx2.to(device)\n",
    "clustery2 = clustery2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88089, 1, 12])\n",
      "torch.Size([23500, 1, 12])\n",
      "tensor([[ 0.0303,  0.0283, -0.0191,  0.0382, -0.0018, -0.0234],\n",
      "        [ 0.0312,  0.0301, -0.0180,  0.0387, -0.0037, -0.0237],\n",
      "        [ 0.0314,  0.0283, -0.0198,  0.0389, -0.0017, -0.0232],\n",
      "        ...,\n",
      "        [ 0.0307,  0.0282, -0.0189,  0.0379, -0.0024, -0.0235],\n",
      "        [ 0.0305,  0.0283, -0.0194,  0.0386, -0.0016, -0.0233],\n",
      "        [ 0.0306,  0.0284, -0.0190,  0.0383, -0.0020, -0.0235]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "inputs = clusterx\n",
    "target = clustery\n",
    "\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5, momentum = .9)\n",
    "\n",
    "best_loss = BAD_LOSS\n",
    "running_dev_loss = 0\n",
    "badcount = 0\n",
    "t = time.time()\n",
    "\n",
    "a = torch.rand(23500, 1, 12)\n",
    "print(clusterx.size())\n",
    "print(a.size())\n",
    "print(model(clusterx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following would be used to start the process, but we want to resume instead"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clusterx.requires_grad=True\n",
    "clustery.requires_grad = True\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5, momentum = .9)\n",
    "start_time = time.time()\n",
    "model.train()\n",
    "\n",
    "ran = range(85000)\n",
    "n=0\n",
    "\n",
    "for epoch in range(1000):\n",
    "# for epoch in range(100000):\n",
    "    model.train()\n",
    "    t = time.time()\n",
    "    k=random.sample(ran, len(ran))\n",
    "    running_loss = 0\n",
    "    for i in range(850):\n",
    "        inputs = clusterx[k[i*100:(i+1)*100]]\n",
    "        target = clustery[k[i*100:(i+1)*100]]\n",
    "        optimizer.zero_grad()#zero parameter gradients\n",
    "\n",
    "        #forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        getloss = loss.item()\n",
    "        running_loss = getloss + running_loss\n",
    "\n",
    "    n=n+1\n",
    "    if n % 1 == 0:\n",
    "        model.eval()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            dev_outputs = model.forward(clusterx)\n",
    "            dev_loss = criterion(dev_outputs, clustery)\n",
    "        print( (n, time.time()-t, running_loss, dev_loss.item()))\n",
    "    if n % 10 == 0:\n",
    "        torch.save(model.state_dict(), 'intermediatemodel.pt')\n",
    "        \n",
    "        \n",
    "print('Finished Training')\n",
    "print('Best dev loss = %.5f' % running_loss)\n",
    "print('Total run time in minutes = %' % ((time.time - start_time)/60))\n",
    "torch.save(model.state_dict(), 'modelfullparsec2.pt')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume(savept, n=0):\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(savept))\n",
    "    model=model.to(device)    \n",
    "    \n",
    "    clusterx.requires_grad=True\n",
    "    clustery.requires_grad=True\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5, momentum = .9)\n",
    "    start_time = time.time()\n",
    "    ran = range(85000)\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        t = time.time()\n",
    "        k=random.sample(ran, len(ran))\n",
    "        running_loss = 0\n",
    "        for i in range(850):\n",
    "            inputs = clusterx[k[i*100:(i+1)*100]]\n",
    "            target = clustery[k[i*100:(i+1)*100]]\n",
    "            optimizer.zero_grad()#zero parameter gradients\n",
    "\n",
    "            #forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            getloss = loss.item()\n",
    "            running_loss = getloss + running_loss\n",
    "\n",
    "        n=n+1\n",
    "        if n % 1 == 0:\n",
    "            model.eval()\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                dev_outputs = model.forward(clusterx)\n",
    "                dev_loss = criterion(dev_outputs, clustery)\n",
    "            print( (n, time.time()-t, running_loss, dev_loss.item()))\n",
    "        if n % 10 == 0:\n",
    "            torch.save(model.state_dict(), 'intermediatemodel.pt')\n",
    "            pickle.dump(n, open('ncount.pickle','wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "N = pickle.load(open('ncount.pickle', 'rb'))\n",
    "resume('intermediatemodel.pt', n=N)\n",
    "\n",
    "#It's pretty safe to say that this has now converged, to an extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=288370</i>\n",
       "<table id=\"table2257236713936\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>SOURCE_ID</th><th>LABELS</th><th>PROB</th><th>RA</th><th>DEC</th><th>PARALLAX</th><th>VLSRRA</th><th>VLSRDEC</th><th>BP_RP</th><th>ABSG</th><th>L</th><th>L1</th><th>B</th><th>AGE</th><th>av</th><th>PHOT_G_MEAN_FLUX</th><th>PHOT_G_MEAN_FLUX_ERROR</th><th>PHOT_G_MEAN_MAG</th><th>PHOT_BP_MEAN_FLUX</th><th>PHOT_BP_MEAN_FLUX_ERROR</th><th>PHOT_BP_MEAN_MAG</th><th>PHOT_RP_MEAN_FLUX</th><th>PHOT_RP_MEAN_FLUX_ERROR</th><th>PHOT_RP_MEAN_MAG</th><th>PARALLAX_ERROR</th><th>VLSRL</th><th>VLSRB</th><th>SLABEL</th><th>RADIAL_VELOCITY</th><th>RADIAL_VELOCITY_ERROR</th><th>VLSRV</th><th>J_M</th><th>J_MSIGCOM</th><th>H_M</th><th>H_MSIGCOM</th><th>KS_M</th><th>KS_MSIGCOM</th><th>W1MPRO</th><th>W1MPRO_ERROR</th><th>W2MPRO</th><th>W2MPRO_ERROR</th><th>W3MPRO</th><th>W3MPRO_ERROR</th><th>W4MPRO</th><th>W4MPRO_ERROR</th><th>NAME</th><th>PLOTNAME</th><th>ID</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>int32</th><th>float32</th><th>float64</th><th>float64</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float64</th><th>float64</th><th>float64</th><th>float32</th><th>float32</th><th>float64</th><th>float64</th><th>float32</th><th>float64</th><th>float64</th><th>float32</th><th>float64</th><th>float64</th><th>float32</th><th>float64</th><th>float32</th><th>float32</th><th>int32</th><th>float64</th><th>float64</th><th>float64</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>bytes17</th><th>bytes23</th><th>int32</th></tr></thead>\n",
       "<tr><td>2170296628789233152</td><td>682</td><td>0.76858854</td><td>314.70689194180073</td><td>52.329566621578444</td><td>1.7047493</td><td>-2.7944367</td><td>-5.3487525</td><td>2.1167336</td><td>6.8206105</td><td>91.56317025918347</td><td>91.56317025918347</td><td>4.240555592195001</td><td>6.1448393</td><td>1.673481</td><td>10242.902467121192</td><td>53.884176247419276</td><td>15.662308</td><td>2899.306110216472</td><td>85.09694543121097</td><td>16.695654</td><td>11835.86540024834</td><td>172.1274497043808</td><td>14.57892</td><td>0.036259825414414304</td><td>-5.8693695</td><td>-1.4030428</td><td>-1</td><td>nan</td><td>nan</td><td>nan</td><td>12.784</td><td>0.029</td><td>11.77</td><td>0.024</td><td>11.113</td><td>0.026</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>LDN_988e</td><td>LDN_988e (1)</td><td>1</td></tr>\n",
       "<tr><td>2168939865797736576</td><td>682</td><td>0.68571967</td><td>314.90886441228935</td><td>50.377704156902475</td><td>1.7571619</td><td>-4.0396943</td><td>-5.9315767</td><td>0.67275333</td><td>1.5655601</td><td>90.16603181336296</td><td>90.16603181336296</td><td>2.868959494636923</td><td>6.1448393</td><td>1.673481</td><td>1376402.9974730948</td><td>533.215140925598</td><td>10.341501</td><td>785318.5834472583</td><td>920.777542516155</td><td>10.613773</td><td>847929.943294906</td><td>847.7494691680856</td><td>9.94102</td><td>0.041739590794115974</td><td>-7.1230206</td><td>-0.87481856</td><td>-1</td><td>nan</td><td>nan</td><td>nan</td><td>9.453</td><td>0.021</td><td>9.37</td><td>0.016</td><td>9.298</td><td>0.022</td><td>9.239</td><td>0.023</td><td>9.265</td><td>0.02</td><td>9.437</td><td>0.04</td><td>9.374</td><td>nan</td><td>LDN_988e</td><td>LDN_988e (1)</td><td>1</td></tr>\n",
       "<tr><td>2168944298210166016</td><td>682</td><td>0.7721724</td><td>315.44785979176584</td><td>50.30612989441009</td><td>1.5677166</td><td>-2.5051455</td><td>-5.2310324</td><td>2.4937096</td><td>7.102591</td><td>90.33870042353638</td><td>90.33870042353638</td><td>2.562848847906288</td><td>6.1448393</td><td>1.673481</td><td>6681.055925424997</td><td>40.578218399358654</td><td>16.126253</td><td>1420.5292939731612</td><td>44.561939754954835</td><td>17.470263</td><td>8206.290766804868</td><td>167.7014557175414</td><td>14.976553</td><td>0.05041082139407983</td><td>-5.5732546</td><td>-1.6057041</td><td>-1</td><td>nan</td><td>nan</td><td>nan</td><td>13.155</td><td>0.022</td><td>12.211</td><td>0.021</td><td>11.848</td><td>0.027</td><td>11.35</td><td>0.023</td><td>10.978</td><td>0.022</td><td>9.295</td><td>0.042</td><td>7.173</td><td>0.095</td><td>LDN_988e</td><td>LDN_988e (1)</td><td>1</td></tr>\n",
       "<tr><td>2168946875190510464</td><td>682</td><td>0.7110925</td><td>315.3347786968243</td><td>50.33555337422311</td><td>1.599027</td><td>-3.3392544</td><td>-5.5588126</td><td>1.7517471</td><td>5.0354056</td><td>90.31310955312907</td><td>90.31310955312907</td><td>2.6365046305879867</td><td>6.1448393</td><td>1.673481</td><td>46654.71890709048</td><td>512.4988737009248</td><td>14.016127</td><td>15542.928811589301</td><td>712.3594820746923</td><td>14.872556</td><td>45336.14439523501</td><td>1429.2217123928838</td><td>13.120809</td><td>0.017662063467430107</td><td>-6.374369</td><td>-1.1909817</td><td>-1</td><td>nan</td><td>nan</td><td>nan</td><td>11.68</td><td>0.021</td><td>10.856</td><td>0.017</td><td>10.289</td><td>0.022</td><td>9.515</td><td>0.023</td><td>8.917</td><td>0.02</td><td>7.286</td><td>0.018</td><td>6.005</td><td>0.046</td><td>LDN_988e</td><td>LDN_988e (1)</td><td>1</td></tr>\n",
       "<tr><td>2168950581742335616</td><td>682</td><td>0.9102174</td><td>315.55931904844766</td><td>50.36047407882485</td><td>1.7437564</td><td>-2.5445793</td><td>-5.3477407</td><td>2.306903</td><td>6.7165947</td><td>90.42660116133291</td><td>90.42660116133291</td><td>2.545414396134979</td><td>6.1448393</td><td>1.673481</td><td>11794.513234228565</td><td>27.279547570041885</td><td>15.509166</td><td>3159.781784059732</td><td>44.24357739733449</td><td>16.602245</td><td>15368.476959480466</td><td>270.24554763297573</td><td>14.295342</td><td>0.0490561929855524</td><td>-5.684296</td><td>-1.6619238</td><td>-1</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>LDN_988e</td><td>LDN_988e (1)</td><td>1</td></tr>\n",
       "<tr><td>2168955151587411072</td><td>682</td><td>0.8176937</td><td>315.5117231752189</td><td>50.4949443486175</td><td>1.6295545</td><td>-2.6513894</td><td>-5.3867946</td><td>1.145791</td><td>2.7946603</td><td>90.5074663110749</td><td>90.5074663110749</td><td>2.6571101455766852</td><td>6.1448393</td><td>1.673481</td><td>381610.3384178202</td><td>87.08550100776637</td><td>11.734316</td><td>176594.57183657322</td><td>166.39372863169547</td><td>12.233945</td><td>294785.8544708823</td><td>206.6661188395169</td><td>11.088154</td><td>0.02551326077642788</td><td>-5.7856493</td><td>-1.6042697</td><td>-1</td><td>-12.552853360072566</td><td>1.0701986299633248</td><td>-0.0886239466723161</td><td>10.281</td><td>0.021</td><td>9.978</td><td>0.019</td><td>9.876</td><td>0.022</td><td>9.775</td><td>0.023</td><td>9.771</td><td>0.021</td><td>9.626</td><td>0.048</td><td>7.666</td><td>0.116</td><td>LDN_988e</td><td>LDN_988e (1)</td><td>1</td></tr>\n",
       "<tr><td>2168955533844548096</td><td>682</td><td>1.0</td><td>315.51420614155546</td><td>50.49953999162996</td><td>1.7215203</td><td>-3.5272715</td><td>-5.1660175</td><td>2.8698845</td><td>7.734706</td><td>90.51196296343467</td><td>90.51196296343467</td><td>2.6589643954102584</td><td>6.1448393</td><td>1.673481</td><td>4500.783642873504</td><td>8.35927402939735</td><td>16.555145</td><td>754.2740678570366</td><td>11.679365435111956</td><td>18.157566</td><td>6161.625812617854</td><td>48.986687810535386</td><td>15.287682</td><td>0.061560148132033324</td><td>-6.203509</td><td>-0.8036534</td><td>-1</td><td>nan</td><td>nan</td><td>nan</td><td>13.237</td><td>0.06</td><td>12.289</td><td>0.065</td><td>11.879</td><td>0.094</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>LDN_988e</td><td>LDN_988e (1)</td><td>1</td></tr>\n",
       "<tr><td>2168958901098918528</td><td>682</td><td>0.9973055</td><td>315.2883636636069</td><td>50.36242411610956</td><td>1.6759953</td><td>-3.396986</td><td>-5.196422</td><td>1.4857779</td><td>2.689424</td><td>90.31378288294434</td><td>90.31378288294434</td><td>2.676489697375864</td><td>6.1448393</td><td>1.673481</td><td>444756.4990598864</td><td>1713.3330020358874</td><td>11.56806</td><td>176721.81104279603</td><td>1689.542832569218</td><td>12.233163</td><td>403472.43576449493</td><td>4194.378879136757</td><td>10.747385</td><td>0.02367974726143494</td><td>-6.1421475</td><td>-0.90351456</td><td>-1</td><td>nan</td><td>nan</td><td>nan</td><td>9.88</td><td>0.02</td><td>9.288</td><td>0.017</td><td>8.556</td><td>0.02</td><td>7.142</td><td>0.038</td><td>6.127</td><td>0.035</td><td>3.883</td><td>0.015</td><td>1.44</td><td>0.02</td><td>LDN_988e</td><td>LDN_988e (1)</td><td>1</td></tr>\n",
       "<tr><td>2170293639492240384</td><td>682</td><td>0.7361647</td><td>315.2581602989653</td><td>52.48528253646384</td><td>1.9271299</td><td>-3.4742708</td><td>-5.2473803</td><td>nan</td><td>nan</td><td>91.90197776253439</td><td>91.90197776253439</td><td>4.088380294032973</td><td>6.1448393</td><td>1.673481</td><td>1060.7517405232609</td><td>2.043976324540662</td><td>18.12433</td><td>67.06986320649928</td><td>5.80847238886815</td><td>20.78507</td><td>1739.6474225945149</td><td>8.591603655901668</td><td>16.660767</td><td>0.1404486702039244</td><td>-6.2331066</td><td>-0.8682965</td><td>-1</td><td>nan</td><td>nan</td><td>nan</td><td>14.148</td><td>0.029</td><td>13.252</td><td>0.032</td><td>12.923</td><td>0.041</td><td>12.684</td><td>0.033</td><td>12.484</td><td>0.032</td><td>11.611</td><td>0.288</td><td>9.267</td><td>0.492</td><td>LDN_988e</td><td>LDN_988e (1)</td><td>1</td></tr>\n",
       "<tr><td>2169124068363304192</td><td>682</td><td>1.0</td><td>316.29874557139937</td><td>50.388655164270794</td><td>1.4513856</td><td>-2.9227438</td><td>-4.198964</td><td>nan</td><td>nan</td><td>90.76172955110428</td><td>90.76172955110428</td><td>2.2121515704382713</td><td>6.1448393</td><td>1.673481</td><td>1286.2793548268678</td><td>1.8106998699385632</td><td>17.915028</td><td>152.1651594656194</td><td>8.56914806227995</td><td>19.8956</td><td>1970.5452685983835</td><td>9.873948030893834</td><td>16.525454</td><td>0.13981249771318333</td><td>-5.072781</td><td>-0.6637926</td><td>-1</td><td>nan</td><td>nan</td><td>nan</td><td>14.339</td><td>0.037</td><td>13.544</td><td>0.043</td><td>13.177</td><td>0.034</td><td>13.002</td><td>0.026</td><td>12.896</td><td>0.027</td><td>12.803</td><td>nan</td><td>9.333</td><td>nan</td><td>LDN_988e</td><td>LDN_988e (1)</td><td>1</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>4581848988000613888</td><td>871</td><td>1.0</td><td>265.7434824399449</td><td>25.86803575290562</td><td>1.3814977</td><td>2.1873412</td><td>-16.798967</td><td>0.9391346</td><td>5.087631</td><td>50.21388553295364</td><td>50.21388553295364</td><td>25.761918473025172</td><td>9.952755</td><td>0.12438733</td><td>33188.996687497034</td><td>6.512895401585527</td><td>14.38588</td><td>16983.968367783895</td><td>22.268601874800115</td><td>14.77629</td><td>23437.199928700662</td><td>20.671727403986644</td><td>13.837155</td><td>0.020436987146953745</td><td>-15.105615</td><td>-7.6687775</td><td>302</td><td>nan</td><td>nan</td><td>nan</td><td>13.171</td><td>0.025</td><td>12.764</td><td>0.034</td><td>12.738</td><td>0.031</td><td>12.68</td><td>0.024</td><td>12.745</td><td>0.025</td><td>12.153</td><td>nan</td><td>8.688</td><td>nan</td><td></td><td>Theia 1641</td><td>1641</td></tr>\n",
       "<tr><td>4576812945568199936</td><td>871</td><td>1.0</td><td>268.65195430340304</td><td>21.213668381675447</td><td>1.7984223</td><td>2.4334075</td><td>-20.556452</td><td>0.88402843</td><td>4.9077992</td><td>46.476437923934014</td><td>46.476437923934014</td><td>21.63119986079046</td><td>9.952755</td><td>0.12438733</td><td>66375.8125512002</td><td>10.143578233923192</td><td>13.633341</td><td>34783.094410864986</td><td>32.490980311958474</td><td>13.997968</td><td>45623.8758735219</td><td>37.47163399869842</td><td>13.113939</td><td>0.018691531451597167</td><td>-18.121273</td><td>-10.005431</td><td>302</td><td>nan</td><td>nan</td><td>nan</td><td>12.517</td><td>0.023</td><td>12.188</td><td>0.021</td><td>12.132</td><td>0.029</td><td>12.069</td><td>0.023</td><td>12.112</td><td>0.023</td><td>12.325</td><td>0.368</td><td>8.593</td><td>nan</td><td></td><td>Theia 1641</td><td>1641</td></tr>\n",
       "<tr><td>4577182042184887552</td><td>871</td><td>1.0</td><td>268.15955978509254</td><td>22.350098583878385</td><td>1.4717305</td><td>2.1907227</td><td>-17.50689</td><td>1.6498384</td><td>7.224689</td><td>47.435101506798446</td><td>47.435101506798446</td><td>22.47445282893886</td><td>9.952755</td><td>0.12438733</td><td>5261.710112298265</td><td>2.258765191019718</td><td>16.385548</td><td>1867.7727076696142</td><td>6.917754134455832</td><td>17.173079</td><td>4959.888419231478</td><td>7.611792290877364</td><td>15.52324</td><td>0.04789997071961712</td><td>-15.469071</td><td>-8.48518</td><td>302</td><td>nan</td><td>nan</td><td>nan</td><td>14.496</td><td>0.031</td><td>13.878</td><td>0.042</td><td>13.65</td><td>0.04</td><td>13.591</td><td>0.025</td><td>13.688</td><td>0.03</td><td>12.389</td><td>nan</td><td>9.264</td><td>nan</td><td></td><td>Theia 1641</td><td>1641</td></tr>\n",
       "<tr><td>4577289244564024192</td><td>871</td><td>1.0</td><td>268.2909401531781</td><td>22.63032401745916</td><td>1.5641541</td><td>2.1181989</td><td>-18.433697</td><td>1.4967813</td><td>6.778746</td><td>47.765343607362695</td><td>47.765343607362695</td><td>22.4630130546635</td><td>9.952755</td><td>0.12438733</td><td>8962.045697424095</td><td>3.1800827388715054</td><td>15.807348</td><td>3457.5290338508344</td><td>11.803591934936145</td><td>16.504473</td><td>7974.281114687994</td><td>12.645130045746797</td><td>15.007691</td><td>0.03753624113689545</td><td>-16.368929</td><td>-8.737624</td><td>302</td><td>nan</td><td>nan</td><td>nan</td><td>14.076</td><td>0.031</td><td>13.445</td><td>0.035</td><td>13.362</td><td>0.051</td><td>13.241</td><td>0.024</td><td>13.356</td><td>0.027</td><td>12.464</td><td>0.386</td><td>9.201</td><td>nan</td><td></td><td>Theia 1641</td><td>1641</td></tr>\n",
       "<tr><td>4502971088977805824</td><td>871</td><td>1.0</td><td>268.1325805331882</td><td>17.396773265778112</td><td>1.0972205</td><td>0.9400358</td><td>-13.5016165</td><td>0.96653175</td><td>5.268329</td><td>42.49456477755756</td><td>42.49456477755756</td><td>20.623886173087353</td><td>9.952755</td><td>0.12438733</td><td>17725.66046821306</td><td>6.262136581416387</td><td>15.066859</td><td>8942.360384751657</td><td>30.977428458870236</td><td>15.472757</td><td>12655.458448975565</td><td>14.767563664765074</td><td>14.506226</td><td>0.03086378547451211</td><td>-12.016677</td><td>-6.2271013</td><td>302</td><td>nan</td><td>nan</td><td>nan</td><td>13.918</td><td>0.026</td><td>13.463</td><td>0.033</td><td>13.442</td><td>0.035</td><td>13.395</td><td>0.024</td><td>13.514</td><td>0.028</td><td>12.414</td><td>nan</td><td>8.714</td><td>nan</td><td></td><td>Theia 1641</td><td>1641</td></tr>\n",
       "<tr><td>4503483186517994880</td><td>871</td><td>1.0</td><td>269.8242007472713</td><td>18.561673729000578</td><td>1.431288</td><td>1.8502295</td><td>-17.289463</td><td>1.5012007</td><td>7.384056</td><td>44.30722464484815</td><td>44.30722464484815</td><td>19.59983564672566</td><td>9.952755</td><td>0.12438733</td><td>4297.1251892152195</td><td>2.658979403490018</td><td>16.605421</td><td>1649.709916172328</td><td>7.57493500416936</td><td>17.307869</td><td>3820.3282087262132</td><td>11.360426039616403</td><td>15.806668</td><td>0.061216933220490176</td><td>-15.145857</td><td>-8.541188</td><td>302</td><td>nan</td><td>nan</td><td>nan</td><td>14.718</td><td>0.043</td><td>14.253</td><td>0.056</td><td>14.169</td><td>0.069</td><td>13.959</td><td>0.027</td><td>13.949</td><td>0.037</td><td>12.497</td><td>nan</td><td>8.385</td><td>nan</td><td></td><td>Theia 1641</td><td>1641</td></tr>\n",
       "<tr><td>4503496724254665216</td><td>871</td><td>1.0</td><td>270.4509151470649</td><td>18.668909494034786</td><td>1.350933</td><td>1.4541453</td><td>-16.355696</td><td>1.0047417</td><td>5.091373</td><td>44.65835689881841</td><td>44.65835689881841</td><td>19.095368105790726</td><td>9.952755</td><td>0.12438733</td><td>31627.49297166064</td><td>11.141162648066778</td><td>14.438204</td><td>15800.455151624088</td><td>27.600174265166622</td><td>14.854714</td><td>23162.15648555008</td><td>24.83561496120196</td><td>13.849973</td><td>0.05337118531672263</td><td>-14.433609</td><td>-7.829064</td><td>302</td><td>nan</td><td>nan</td><td>nan</td><td>13.096</td><td>0.026</td><td>12.676</td><td>0.03</td><td>12.63</td><td>0.025</td><td>12.547</td><td>0.023</td><td>12.574</td><td>0.024</td><td>12.079</td><td>0.275</td><td>9.142</td><td>nan</td><td></td><td>Theia 1641</td><td>1641</td></tr>\n",
       "<tr><td>4527638769787728512</td><td>871</td><td>1.0</td><td>270.6556650284764</td><td>19.73846396906154</td><td>1.5798798</td><td>1.9630368</td><td>-19.168705</td><td>1.3121262</td><td>6.3489437</td><td>45.78119656925632</td><td>45.78119656925632</td><td>19.334383439595992</td><td>9.952755</td><td>0.12438733</td><td>13583.660299557187</td><td>3.6301613192909112</td><td>15.3558235</td><td>5778.530481792524</td><td>12.429600893980128</td><td>15.946845</td><td>11242.955750315394</td><td>11.771882062040962</td><td>14.634719</td><td>0.032461073084525206</td><td>-16.862383</td><td>-9.32485</td><td>302</td><td>nan</td><td>nan</td><td>nan</td><td>13.757</td><td>0.026</td><td>13.251</td><td>0.032</td><td>13.088</td><td>0.03</td><td>13.077</td><td>0.024</td><td>13.119</td><td>0.028</td><td>12.363</td><td>nan</td><td>8.506</td><td>nan</td><td></td><td>Theia 1641</td><td>1641</td></tr>\n",
       "<tr><td>4528165813814176640</td><td>871</td><td>1.0</td><td>271.77617190518714</td><td>20.66547485770778</td><td>1.3096106</td><td>1.8479977</td><td>-15.385368</td><td>1.0442743</td><td>3.6168199</td><td>47.11592361550366</td><td>47.11592361550366</td><td>18.72361703827532</td><td>9.952755</td><td>0.12438733</td><td>115585.36677101755</td><td>21.203496013743703</td><td>13.031109</td><td>56003.25744956928</td><td>53.910383292197935</td><td>13.480855</td><td>85140.41900183247</td><td>49.486946947070145</td><td>12.436581</td><td>0.021981144115397692</td><td>-13.433675</td><td>-7.7240562</td><td>302</td><td>3.4536990925601847</td><td>2.058596858640234</td><td>21.428955256887743</td><td>11.712</td><td>0.022</td><td>11.351</td><td>0.022</td><td>11.267</td><td>0.02</td><td>11.209</td><td>0.022</td><td>11.265</td><td>0.021</td><td>11.151</td><td>0.137</td><td>8.491</td><td>nan</td><td></td><td>Theia 1641</td><td>1641</td></tr>\n",
       "<tr><td>4551810467769600640</td><td>871</td><td>0.9965722</td><td>267.53221920823563</td><td>19.3995454349027</td><td>1.1101109</td><td>1.9007696</td><td>-12.7640085</td><td>0.90315914</td><td>4.833529</td><td>44.24114046832548</td><td>44.24114046832548</td><td>21.922655696595115</td><td>9.952755</td><td>0.12438733</td><td>27081.17958865376</td><td>6.146923793574165</td><td>14.606697</td><td>14138.702853698287</td><td>18.001564465583844</td><td>14.975365</td><td>18874.946491604805</td><td>16.755988929195695</td><td>14.072206</td><td>0.022921846767035285</td><td>-11.054489</td><td>-6.6581607</td><td>302</td><td>nan</td><td>nan</td><td>nan</td><td>13.407</td><td>0.029</td><td>13.03</td><td>0.033</td><td>12.996</td><td>0.031</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td>nan</td><td></td><td>Theia 1641</td><td>1641</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=288370>\n",
       "     SOURCE_ID      LABELS    PROB    ...         PLOTNAME          ID \n",
       "       int64        int32   float32   ...         bytes23         int32\n",
       "------------------- ------ ---------- ... ----------------------- -----\n",
       "2170296628789233152    682 0.76858854 ... LDN_988e (1)                1\n",
       "2168939865797736576    682 0.68571967 ... LDN_988e (1)                1\n",
       "2168944298210166016    682  0.7721724 ... LDN_988e (1)                1\n",
       "2168946875190510464    682  0.7110925 ... LDN_988e (1)                1\n",
       "2168950581742335616    682  0.9102174 ... LDN_988e (1)                1\n",
       "2168955151587411072    682  0.8176937 ... LDN_988e (1)                1\n",
       "2168955533844548096    682        1.0 ... LDN_988e (1)                1\n",
       "2168958901098918528    682  0.9973055 ... LDN_988e (1)                1\n",
       "2170293639492240384    682  0.7361647 ... LDN_988e (1)                1\n",
       "2169124068363304192    682        1.0 ... LDN_988e (1)                1\n",
       "                ...    ...        ... ...                     ...   ...\n",
       "4581848988000613888    871        1.0 ... Theia 1641               1641\n",
       "4576812945568199936    871        1.0 ... Theia 1641               1641\n",
       "4577182042184887552    871        1.0 ... Theia 1641               1641\n",
       "4577289244564024192    871        1.0 ... Theia 1641               1641\n",
       "4502971088977805824    871        1.0 ... Theia 1641               1641\n",
       "4503483186517994880    871        1.0 ... Theia 1641               1641\n",
       "4503496724254665216    871        1.0 ... Theia 1641               1641\n",
       "4527638769787728512    871        1.0 ... Theia 1641               1641\n",
       "4528165813814176640    871        1.0 ... Theia 1641               1641\n",
       "4551810467769600640    871  0.9965722 ... Theia 1641               1641"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mwTab = Table.read('.\\\\data\\\\mwclustering-061319.fits')\n",
    "mwTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 9A64-F859\n",
      "\n",
      " Directory of C:\\Users\\sahal\\Desktop\\YSO ML\\Code\\data\n",
      "\n",
      "06/26/2019  01:46 PM    <DIR>          .\n",
      "06/26/2019  01:46 PM    <DIR>          ..\n",
      "06/26/2019  12:14 PM        92,298,240 mwclustering-061319.fits\n",
      "06/26/2019  01:45 PM         1,880,640 Orion+Starhorse.fits\n",
      "               2 File(s)     94,178,880 bytes\n",
      "               2 Dir(s)  196,772,282,368 bytes free\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
